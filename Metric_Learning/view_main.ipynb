{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: [1/100], TRAIN_LOSS: 0.195, VALID_LOSS: 0.185\n",
      "save wieghts to ./weights/resnet50_0.18472.pth\n",
      "EPOCH: [2/100], TRAIN_LOSS: 0.194, VALID_LOSS: 0.140\n",
      "save wieghts to ./weights/resnet50_0.13990.pth\n",
      "EPOCH: [3/100], TRAIN_LOSS: 0.190, VALID_LOSS: 0.122\n",
      "save wieghts to ./weights/resnet50_0.12224.pth\n",
      "EPOCH: [4/100], TRAIN_LOSS: 0.188, VALID_LOSS: 0.131\n",
      "save wieghts to ./weights/resnet50_0.13143.pth\n",
      "EPOCH: [5/100], TRAIN_LOSS: 0.184, VALID_LOSS: 0.144\n",
      "save wieghts to ./weights/resnet50_0.14398.pth\n",
      "EPOCH: [6/100], TRAIN_LOSS: 0.164, VALID_LOSS: 0.107\n",
      "save wieghts to ./weights/resnet50_0.10714.pth\n",
      "EPOCH: [7/100], TRAIN_LOSS: 0.152, VALID_LOSS: 0.151\n",
      "save wieghts to ./weights/resnet50_0.15135.pth\n",
      "EPOCH: [8/100], TRAIN_LOSS: 0.153, VALID_LOSS: 0.134\n",
      "save wieghts to ./weights/resnet50_0.13416.pth\n",
      "EPOCH: [9/100], TRAIN_LOSS: 0.138, VALID_LOSS: 0.093\n",
      "save wieghts to ./weights/resnet50_0.09253.pth\n",
      "EPOCH: [10/100], TRAIN_LOSS: 0.126, VALID_LOSS: 0.068\n",
      "save wieghts to ./weights/resnet50_0.06793.pth\n",
      "EPOCH: [11/100], TRAIN_LOSS: 0.113, VALID_LOSS: 0.067\n",
      "save wieghts to ./weights/resnet50_0.06698.pth\n",
      "EPOCH: [12/100], TRAIN_LOSS: 0.089, VALID_LOSS: 0.129\n",
      "save wieghts to ./weights/resnet50_0.12884.pth\n",
      "EPOCH: [13/100], TRAIN_LOSS: 0.089, VALID_LOSS: 0.098\n",
      "save wieghts to ./weights/resnet50_0.09794.pth\n",
      "EPOCH: [14/100], TRAIN_LOSS: 0.074, VALID_LOSS: 0.080\n",
      "save wieghts to ./weights/resnet50_0.08025.pth\n",
      "EPOCH: [15/100], TRAIN_LOSS: 0.062, VALID_LOSS: 0.123\n",
      "save wieghts to ./weights/resnet50_0.12312.pth\n",
      "EPOCH: [16/100], TRAIN_LOSS: 0.061, VALID_LOSS: 0.108\n",
      "save wieghts to ./weights/resnet50_0.10805.pth\n",
      "EPOCH: [17/100], TRAIN_LOSS: 0.049, VALID_LOSS: 0.090\n",
      "save wieghts to ./weights/resnet50_0.09031.pth\n",
      "EPOCH: [18/100], TRAIN_LOSS: 0.046, VALID_LOSS: 0.076\n",
      "save wieghts to ./weights/resnet50_0.07554.pth\n",
      "EPOCH: [19/100], TRAIN_LOSS: 0.038, VALID_LOSS: 0.100\n",
      "save wieghts to ./weights/resnet50_0.09961.pth\n",
      "EPOCH: [20/100], TRAIN_LOSS: 0.033, VALID_LOSS: 0.067\n",
      "save wieghts to ./weights/resnet50_0.06669.pth\n",
      "EPOCH: [21/100], TRAIN_LOSS: 0.033, VALID_LOSS: 0.062\n",
      "save wieghts to ./weights/resnet50_0.06214.pth\n",
      "EPOCH: [22/100], TRAIN_LOSS: 0.031, VALID_LOSS: 0.063\n",
      "save wieghts to ./weights/resnet50_0.06285.pth\n",
      "EPOCH: [23/100], TRAIN_LOSS: 0.028, VALID_LOSS: 0.063\n",
      "save wieghts to ./weights/resnet50_0.06338.pth\n",
      "EPOCH: [24/100], TRAIN_LOSS: 0.025, VALID_LOSS: 0.065\n",
      "save wieghts to ./weights/resnet50_0.06474.pth\n",
      "EPOCH: [25/100], TRAIN_LOSS: 0.021, VALID_LOSS: 0.063\n",
      "save wieghts to ./weights/resnet50_0.06303.pth\n",
      "EPOCH: [26/100], TRAIN_LOSS: 0.024, VALID_LOSS: 0.031\n",
      "save wieghts to ./weights/resnet50_0.03125.pth\n",
      "EPOCH: [27/100], TRAIN_LOSS: 0.016, VALID_LOSS: 0.061\n",
      "save wieghts to ./weights/resnet50_0.06124.pth\n",
      "EPOCH: [28/100], TRAIN_LOSS: 0.018, VALID_LOSS: 0.036\n",
      "save wieghts to ./weights/resnet50_0.03575.pth\n",
      "EPOCH: [29/100], TRAIN_LOSS: 0.014, VALID_LOSS: 0.058\n",
      "save wieghts to ./weights/resnet50_0.05810.pth\n",
      "EPOCH: [30/100], TRAIN_LOSS: 0.014, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03908.pth\n",
      "EPOCH: [31/100], TRAIN_LOSS: 0.013, VALID_LOSS: 0.022\n",
      "save wieghts to ./weights/resnet50_0.02198.pth\n",
      "EPOCH: [32/100], TRAIN_LOSS: 0.011, VALID_LOSS: 0.021\n",
      "save wieghts to ./weights/resnet50_0.02101.pth\n",
      "EPOCH: [33/100], TRAIN_LOSS: 0.007, VALID_LOSS: 0.032\n",
      "save wieghts to ./weights/resnet50_0.03161.pth\n",
      "EPOCH: [34/100], TRAIN_LOSS: 0.010, VALID_LOSS: 0.046\n",
      "save wieghts to ./weights/resnet50_0.04630.pth\n",
      "EPOCH: [35/100], TRAIN_LOSS: 0.009, VALID_LOSS: 0.025\n",
      "save wieghts to ./weights/resnet50_0.02473.pth\n",
      "EPOCH: [36/100], TRAIN_LOSS: 0.010, VALID_LOSS: 0.053\n",
      "save wieghts to ./weights/resnet50_0.05275.pth\n",
      "EPOCH: [37/100], TRAIN_LOSS: 0.009, VALID_LOSS: 0.021\n",
      "save wieghts to ./weights/resnet50_0.02068.pth\n",
      "EPOCH: [38/100], TRAIN_LOSS: 0.009, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03933.pth\n",
      "EPOCH: [39/100], TRAIN_LOSS: 0.010, VALID_LOSS: 0.042\n",
      "save wieghts to ./weights/resnet50_0.04151.pth\n",
      "EPOCH: [40/100], TRAIN_LOSS: 0.005, VALID_LOSS: 0.030\n",
      "save wieghts to ./weights/resnet50_0.03000.pth\n",
      "EPOCH: [41/100], TRAIN_LOSS: 0.006, VALID_LOSS: 0.043\n",
      "save wieghts to ./weights/resnet50_0.04258.pth\n",
      "EPOCH: [42/100], TRAIN_LOSS: 0.007, VALID_LOSS: 0.045\n",
      "save wieghts to ./weights/resnet50_0.04500.pth\n",
      "EPOCH: [43/100], TRAIN_LOSS: 0.006, VALID_LOSS: 0.021\n",
      "save wieghts to ./weights/resnet50_0.02084.pth\n",
      "EPOCH: [44/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.037\n",
      "save wieghts to ./weights/resnet50_0.03729.pth\n",
      "EPOCH: [45/100], TRAIN_LOSS: 0.006, VALID_LOSS: 0.035\n",
      "save wieghts to ./weights/resnet50_0.03471.pth\n",
      "EPOCH: [46/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.032\n",
      "save wieghts to ./weights/resnet50_0.03217.pth\n",
      "EPOCH: [47/100], TRAIN_LOSS: 0.005, VALID_LOSS: 0.058\n",
      "save wieghts to ./weights/resnet50_0.05786.pth\n",
      "EPOCH: [48/100], TRAIN_LOSS: 0.007, VALID_LOSS: 0.021\n",
      "save wieghts to ./weights/resnet50_0.02130.pth\n",
      "EPOCH: [49/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.032\n",
      "save wieghts to ./weights/resnet50_0.03229.pth\n",
      "EPOCH: [50/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.044\n",
      "save wieghts to ./weights/resnet50_0.04439.pth\n",
      "EPOCH: [51/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.042\n",
      "save wieghts to ./weights/resnet50_0.04215.pth\n",
      "EPOCH: [52/100], TRAIN_LOSS: 0.005, VALID_LOSS: 0.046\n",
      "save wieghts to ./weights/resnet50_0.04573.pth\n",
      "EPOCH: [53/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.042\n",
      "save wieghts to ./weights/resnet50_0.04195.pth\n",
      "EPOCH: [54/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.033\n",
      "save wieghts to ./weights/resnet50_0.03280.pth\n",
      "EPOCH: [55/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.042\n",
      "save wieghts to ./weights/resnet50_0.04197.pth\n",
      "EPOCH: [56/100], TRAIN_LOSS: 0.004, VALID_LOSS: 0.034\n",
      "save wieghts to ./weights/resnet50_0.03375.pth\n",
      "EPOCH: [57/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.036\n",
      "save wieghts to ./weights/resnet50_0.03647.pth\n",
      "EPOCH: [58/100], TRAIN_LOSS: 0.005, VALID_LOSS: 0.028\n",
      "save wieghts to ./weights/resnet50_0.02844.pth\n",
      "EPOCH: [59/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03897.pth\n",
      "EPOCH: [60/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.036\n",
      "save wieghts to ./weights/resnet50_0.03604.pth\n",
      "EPOCH: [61/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.040\n",
      "save wieghts to ./weights/resnet50_0.03967.pth\n",
      "EPOCH: [62/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03949.pth\n",
      "EPOCH: [63/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.042\n",
      "save wieghts to ./weights/resnet50_0.04200.pth\n",
      "EPOCH: [64/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.049\n",
      "save wieghts to ./weights/resnet50_0.04898.pth\n",
      "EPOCH: [65/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.051\n",
      "save wieghts to ./weights/resnet50_0.05131.pth\n",
      "EPOCH: [66/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.048\n",
      "save wieghts to ./weights/resnet50_0.04780.pth\n",
      "EPOCH: [67/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.027\n",
      "save wieghts to ./weights/resnet50_0.02732.pth\n",
      "EPOCH: [68/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.038\n",
      "save wieghts to ./weights/resnet50_0.03766.pth\n",
      "EPOCH: [69/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03930.pth\n",
      "EPOCH: [70/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.040\n",
      "save wieghts to ./weights/resnet50_0.03986.pth\n",
      "EPOCH: [71/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.064\n",
      "save wieghts to ./weights/resnet50_0.06369.pth\n",
      "EPOCH: [72/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.034\n",
      "save wieghts to ./weights/resnet50_0.03387.pth\n",
      "EPOCH: [73/100], TRAIN_LOSS: 0.006, VALID_LOSS: 0.056\n",
      "save wieghts to ./weights/resnet50_0.05649.pth\n",
      "EPOCH: [74/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.033\n",
      "save wieghts to ./weights/resnet50_0.03295.pth\n",
      "EPOCH: [75/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.034\n",
      "save wieghts to ./weights/resnet50_0.03368.pth\n",
      "EPOCH: [76/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.032\n",
      "save wieghts to ./weights/resnet50_0.03177.pth\n",
      "EPOCH: [77/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.048\n",
      "save wieghts to ./weights/resnet50_0.04791.pth\n",
      "EPOCH: [78/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.045\n",
      "save wieghts to ./weights/resnet50_0.04493.pth\n",
      "EPOCH: [79/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.026\n",
      "save wieghts to ./weights/resnet50_0.02584.pth\n",
      "EPOCH: [80/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.027\n",
      "save wieghts to ./weights/resnet50_0.02655.pth\n",
      "EPOCH: [81/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.033\n",
      "save wieghts to ./weights/resnet50_0.03335.pth\n",
      "EPOCH: [82/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save wieghts to ./weights/resnet50_0.05963.pth\n",
      "EPOCH: [83/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.023\n",
      "save wieghts to ./weights/resnet50_0.02297.pth\n",
      "EPOCH: [84/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03886.pth\n",
      "EPOCH: [85/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.072\n",
      "save wieghts to ./weights/resnet50_0.07215.pth\n",
      "EPOCH: [86/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.065\n",
      "save wieghts to ./weights/resnet50_0.06502.pth\n",
      "EPOCH: [87/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.053\n",
      "save wieghts to ./weights/resnet50_0.05330.pth\n",
      "EPOCH: [88/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.043\n",
      "save wieghts to ./weights/resnet50_0.04303.pth\n",
      "EPOCH: [89/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.047\n",
      "save wieghts to ./weights/resnet50_0.04745.pth\n",
      "EPOCH: [90/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.041\n",
      "save wieghts to ./weights/resnet50_0.04143.pth\n",
      "EPOCH: [91/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.030\n",
      "save wieghts to ./weights/resnet50_0.02982.pth\n",
      "EPOCH: [92/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.056\n",
      "save wieghts to ./weights/resnet50_0.05586.pth\n",
      "EPOCH: [93/100], TRAIN_LOSS: 0.002, VALID_LOSS: 0.039\n",
      "save wieghts to ./weights/resnet50_0.03879.pth\n",
      "EPOCH: [94/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.053\n",
      "save wieghts to ./weights/resnet50_0.05278.pth\n",
      "EPOCH: [95/100], TRAIN_LOSS: 0.003, VALID_LOSS: 0.024\n",
      "save wieghts to ./weights/resnet50_0.02409.pth\n",
      "EPOCH: [96/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.034\n",
      "save wieghts to ./weights/resnet50_0.03435.pth\n",
      "EPOCH: [97/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.045\n",
      "save wieghts to ./weights/resnet50_0.04519.pth\n",
      "EPOCH: [98/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.037\n",
      "save wieghts to ./weights/resnet50_0.03675.pth\n",
      "EPOCH: [99/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.055\n",
      "save wieghts to ./weights/resnet50_0.05472.pth\n",
      "EPOCH: [100/100], TRAIN_LOSS: 0.001, VALID_LOSS: 0.013\n",
      "save wieghts to ./weights/resnet50_0.01347.pth\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import TripletSampler, load_datasets, load_test\n",
    "from models import TripletResNet\n",
    "from losses import TripletLoss, TripletAngularLoss\n",
    "from params import args\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(args.img_size),\n",
    "                                transforms.CenterCrop(args.img_size),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "test_dataset = load_test(args.test_json, transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=126)\n",
    "\n",
    "model = TripletResNet(args.output_dim)\n",
    "model = model.to(device)\n",
    "# model.load_state_dict(torch.load('./weights/' + args.experiment_name +'_features'+ str(args.output_dim) + '_Ture.pth'))  #\n",
    "model.load_state_dict(torch.load('./weights/resnet50_0.01347.pth')) #_features256_True\n",
    "model.eval()\n",
    "# model = torchvision.models.__dict__['resnet50'](pretrained=True)\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# AA = model.model[-1]\n",
    "# handle_forward = model.model.register_forward_hook(hook)\n",
    "# handle_backward = model.model.register_backward_hook(hook)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "pred_metric = []\n",
    "y_test = []\n",
    "for i, (anchors, positives, negatives, labels) in enumerate(test_loader):\n",
    "    anchors = anchors.to(device)\n",
    "    positives = positives.to(device)\n",
    "    negatives = negatives.to(device)\n",
    "    metric = model(anchors)\n",
    "    # metric_positives = model(positives)\n",
    "    # metric_negatives = model(negatives)\n",
    "\n",
    "    pred_metric.append(metric.detach().cpu().numpy())\n",
    "    y_test.append(labels.detach().numpy())\n",
    "\n",
    "pred_metric = np.concatenate(pred_metric, 0)\n",
    "y_test = np.concatenate(y_test, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/appl/software/matplotlib/3.0.3-fosscuda-2019a-Python-3.7.2/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Plot t-SNE\n",
    "############################################################\n",
    "y_reduced = TSNE(n_components=2, random_state=0).fit_transform(pred_metric)\n",
    "plt_tSNE = plt\n",
    "plt_tSNE.scatter(y_reduced[y_test == 0, 0], y_reduced[y_test == 0, 1], color='blue')\n",
    "plt_tSNE.scatter(y_reduced[y_test == 1, 0], y_reduced[y_test == 1, 1], color='red')\n",
    "plt_tSNE.scatter(y_reduced[y_test == 2, 0], y_reduced[y_test == 2, 1], color='green')\n",
    "# plt_tSNE.scatter(y_reduced[y_test == 3, 0], y_reduced[y_test == 3, 1], color='black')\n",
    "\n",
    "plt_tSNE.legend(['Covid19 Infected', 'Healthy', 'Tuberculosis'], loc='upper left')\n",
    "plt_tSNE.savefig(args.experiment_name + '_tSNE.png')\n",
    "plt_tSNE.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# Plot Comparing Result\n",
    "############################################################\n",
    "n_queries = 3\n",
    "xp_idx0 = np.random.choice(np.where(labels == 0)[0])\n",
    "xp_idx1 = np.random.choice(np.where(labels == 1)[0])\n",
    "xp_idx2 = np.random.choice(np.where(labels == 2)[0])\n",
    "# xp_idx3 = np.random.choice(np.where(labels == 3)[0])\n",
    "\n",
    "# queries = [xp_idx0, xp_idx1, xp_idx2, xp_idx3]\n",
    "queries = [xp_idx0, xp_idx1, xp_idx2]\n",
    "queries_metric = metric[queries, :]\n",
    "\n",
    "\n",
    "euc_dist = torch.cdist(queries_metric, metric, p=2)\n",
    "cloeset_50_value, cloeset_50_pos = torch.topk(euc_dist, 42, dim=1, largest=False, sorted=True, out=None)\n",
    "cloeset_50_pos = cloeset_50_pos.cpu()\n",
    "\n",
    "##################### Visualise the gradients map w.r.t raw image\n",
    "plt_Compare = plt\n",
    "plt_Compare.clf()\n",
    "f, axarr = plt_Compare.subplots(n_queries, 1, gridspec_kw={'wspace': 0, 'hspace': 0})\n",
    "for i in range(n_queries):\n",
    "    ax = axarr[i]\n",
    "    # img_t = torch.cat((anchors[queries[i], :, :, :].unsqueeze(0), anchors[cloeset_50_pos[i, :], :, :, :]))\n",
    "    img_t = anchors[cloeset_50_pos[i, 0:5], :, :, :]\n",
    "    plot_out = torchvision.utils.make_grid(img_t, nrow=5, normalize=True, padding=1)\n",
    "    plot_out = plot_out.cpu()\n",
    "    plot_out.size()\n",
    "    image_transposed = plot_out.permute([1, 2, 0])\n",
    "    ax.imshow(image_transposed)\n",
    "    ax.axis('off')\n",
    "plt_Compare.savefig(args.experiment_name + '_Comparring.png')\n",
    "f.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9837)\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Calculating mAP\n",
    "############################################################\n",
    "def th_delete(tensor, indices):\n",
    "    mask = torch.ones(tensor.numel(), dtype=torch.bool)\n",
    "    mask[indices] = False\n",
    "    return tensor[mask]\n",
    "\n",
    "predict_label = torch.cat(([labels[cloeset_50_pos[0, 1:]], labels[cloeset_50_pos[1, 1:]], labels[cloeset_50_pos[2, 1:]]]), 0)\n",
    "labels = th_delete(labels, queries)\n",
    "torch.sum(predict_label == labels)\n",
    "accuracy_rate = torch.sum(predict_label == labels)/len(labels)\n",
    "print(accuracy_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/appl/software/matplotlib/3.0.3-fosscuda-2019a-Python-3.7.2/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    " ############################################################\n",
    "# Plot Confusion Matrix\n",
    "############################################################\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# classes = ['CAP', 'Covid', 'HC', 'SPT']\n",
    "classes = ['COVID', 'NORMAL', 'TUBER']\n",
    "\n",
    "cm = confusion_matrix(labels, predict_label, labels=None, sample_weight=None)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm = np.around(cm, decimals=2)\n",
    "f = plt.figure(figsize=(15, 10), dpi=300)\n",
    "ax = plt.subplot(111)\n",
    "df = pd.DataFrame(cm, index=classes, columns=classes)\n",
    "sns.heatmap(df, cmap='Blues', annot=True, fmt='g')\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_ylabel('True', fontsize=15)\n",
    "ax.set_xlabel('Pred', fontsize=15)\n",
    "ax.tick_params(axis='y', labelsize=15, labelrotation=45)  # y axis\n",
    "ax.tick_params(axis='x', labelsize=15)  # x axis\n",
    "f.savefig('%s.jpg' % 'Confusion_Matrix', bbox_inches='tight')\n",
    "f.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9837301587301588 0.983739837398374\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "ma_f1 = f1_score(labels, predict_label, average='macro')\n",
    "mi_f1 = f1_score(labels, predict_label, average='micro')\n",
    "print(ma_f1, mi_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/appl/software/matplotlib/3.0.3-fosscuda-2019a-Python-3.7.2/lib/python3.7/site-packages/matplotlib/figure.py:445: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  % get_backend())\n"
     ]
    }
   ],
   "source": [
    " ############################################################\n",
    "# Plot ROC curve, and PR curve\n",
    "############################################################\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "num_classes = 3\n",
    "# scores = torch.softmax(output, dim=1).detach().numpy()\n",
    "scores = label_binarize(predict_label, classes=list(range(num_classes))) # out = model(data)\n",
    "binary_label = label_binarize(labels, classes=list(range(num_classes)))  # num_classes=10\n",
    "\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(binary_label[:, i], scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(binary_label.ravel(), scores.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(num_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= num_classes\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Multi-class ROC.jpg', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 24,  32,  42,  28,  30,  78,  48,  13,  73,  57,  75,  18,  50,  54,\n",
       "          26,   5,  65,  58,  14,  76,   1,  44,  10,   2,  70,  52,  21,  83],\n",
       "        [ 81,  43,  79,  46,  68,  58,  51,  54,  80,  55,  61,  67,  52,  62,\n",
       "          59,  64,  49,  66,  57,  50,  74,  60,  72,  71,  47,  82,  44,  56],\n",
       "        [ 96, 116,  86,  85,  95, 113, 103, 101,  97, 107,  89,  87, 119, 125,\n",
       "         117, 123, 109,  98,  90, 100, 108, 120, 110,  94,  91, 115, 105,  93]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################################################\n",
    "\n",
    "predict_label = torch.reshape(predict_label, (4, 27))\n",
    "labels = torch.reshape(labels, (4, 27))\n",
    "\n",
    "TP0 = torch.sum(predict_label[0, :] == labels[0, :])/len(labels[0, :])\n",
    "FP0 = torch.sum(predict_label[0, :] != labels[0, :])/len(labels[0, :])\n",
    "FN0 = torch.sum(predict_label[0, :] != labels[0, :])/len(labels[0, :])\n",
    "\n",
    "TP1 = torch.sum(predict_label[1, :] == labels[1, :])/len(labels[1, :])\n",
    "FP1 = torch.sum(predict_label[1, :] != labels[1, :])/len(labels[1, :])\n",
    "FN1 = torch.sum(predict_label[1, :] != labels[1, :])/len(labels[1, :])\n",
    "\n",
    "TP2 = torch.sum(predict_label[2, :] == labels[1, :])/len(labels[2, :])\n",
    "FP2 = torch.sum(predict_label[2, :] != labels[1, :])/len(labels[2, :])\n",
    "FN2 = torch.sum(predict_label[2, :] != labels[1, :])/len(labels[2, :])\n",
    "\n",
    "\n",
    "accuracy_rate_0 = torch.sum(predict_label[0, :] == labels[0, :])/len(labels[0, :])\n",
    "accuracy_rate_1 = torch.sum(predict_label[1, :] == labels[1, :])/len(labels[1, :])\n",
    "accuracy_rate_2 = torch.sum(predict_label[2, :] == labels[2, :])/len(labels[2, :])\n",
    "# accuracy_rate_3 = torch.sum(predict_label[3, :] == labels[3, :])/len(labels[3, :])\n",
    "\n",
    "from sklearn import metrics\n",
    "aps = []\n",
    "for y_t, y_s in zip(labels, predict_label):\n",
    "    ap = metrics.average_precision_score(y_t, y_s)\n",
    "    aps.append(ap)\n",
    "np.mean(np.array(aps))\n",
    "\n",
    "ha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
